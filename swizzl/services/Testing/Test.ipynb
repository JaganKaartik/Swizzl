{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "path = '/Volumes/JK/Swizzl/swizzl/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "from services.mlearning import sentiment as st\n",
    "from services.mlearning import prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkText(link):\n",
    "    url = \"{}\".format(link)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content,\"lxml\")\n",
    "    article_text = ''\n",
    "    mylink = soup.find('div').findAll('p')\n",
    "    for i in mylink:\n",
    "        article_text += ''.join(i.findAll(text = True))\n",
    "    return article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YahooFetch():\n",
    "    url = \"https://news.yahoo.com/rss/\"\n",
    "    url = requests.get(url)\n",
    "    soup = BeautifulSoup(url.text,'xml')\n",
    "    \n",
    "    try:\n",
    "        # Fetch All Required items\n",
    "        titles = soup.findAll('title')\n",
    "        links = soup.findAll('link')\n",
    "        pubDates = soup.findAll('pubDate')\n",
    "\n",
    "    except Exception as e :\n",
    "        \n",
    "        # Return Empty if titles, links, descriptions, pubdates not found\n",
    "        print(e)\n",
    "        return \"Error\"\n",
    "\n",
    "    # We don't want the first elements as these are just metadata\n",
    "    \n",
    "    titles.pop(0)\n",
    "    titles.pop(0)\n",
    "    links.pop(0)\n",
    "    links.pop(0)\n",
    "    pubDates.pop(0)\n",
    "\n",
    "    #Dictionary to hold crawled information\n",
    "    \n",
    "\n",
    "\n",
    "    FeedDict = {}\n",
    "    temp = []\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Add titles to the Dictionary\n",
    "        \n",
    "        for i in titles:\n",
    "            temp.append(i.get_text())\n",
    "            FeedDict['title'] = temp\n",
    "            \n",
    "        # Add link and details regarding text contetn @ link to the Dictionary\n",
    "        \n",
    "        temp = []\n",
    "        temptext = []\n",
    "        tbscore = []\n",
    "        vadscore = []\n",
    "        profvalue = []\n",
    "        for i in links:\n",
    "            \n",
    "            # Append Links\n",
    "            temp.append(i.get_text())\n",
    "            \n",
    "            # Append Text Content from Links\n",
    "            textval = linkText(i.get_text())\n",
    "            textval = re.sub('\\\"','\\\\\"',textval)\n",
    "            textval = \" \\\" \" + textval + \" \\\" \"\n",
    "            temptext.append(textval)\n",
    "            \n",
    "            # Find Subjectivity, Objectivity of text content\n",
    "            score = st.sentimentTB(textval)\n",
    "            tbscore.append(score)\n",
    "            \n",
    "            # Find Sentiment of text content\n",
    "            score = st.sentimentVader(textval)\n",
    "            vadscore.append(score)\n",
    "            \n",
    "            # Find Profanity Score of content\n",
    "            textval = [textval]\n",
    "            score = float(prof.predProf(textval))\n",
    "            profvalue.append(score)\n",
    "            \n",
    "            # Add to Feeds Dictionary \n",
    "            FeedDict['link'] = temp\n",
    "            FeedDict['linktext'] = temptext\n",
    "            FeedDict['tbScore'] = tbscore\n",
    "            FeedDict['vaderScore'] = vadscore\n",
    "            FeedDict['prof'] = profvalue\n",
    "            \n",
    "        # Add Published Dates to the Dictionary\n",
    "        temp = []\n",
    "        for i in pubDates:\n",
    "            temp.append(i.get_text())\n",
    "            FeedDict['pubdate'] = temp\n",
    "        \n",
    "        print(\"Success\")\n",
    "    except Exception as e :\n",
    "        print(e)\n",
    "        return \"Error\"\n",
    "    \n",
    "    return FeedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "FeedDict = YahooFetch()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,54):\n",
    "    print(FeedDict['title'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0,len(FeedDict['title'])):\n",
    "    if(re.findall(\"^https://news.yahoo.com\",FeedDict['link'][i])):\n",
    "        count = count + 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \" Police breached a Hong Kong university campus held by protesters early Monday after an all-night siege that included firing repeated barrages of tear gas and water cannons.Anti-government protesters have barricaded themselves inside Hong Kong Polytechnic University for days. Police surrounded the area Sunday night and began moving in after issuing an ultimatum for people to leave the area. The crowd wore raincoats and carried umbrellas to shield themselves.Riot officers broke in one entrance before dawn as fires raged inside and outside the school, but they didn’t appear to get very far. Fiery explosions could be seen as protesters responded with gasoline bombs. Police, who have warned that everyone in the area could be charged with rioting, reportedly made a handful of arrests.At daybreak, protesters remained in control of most of the campus. In one outdoor area, some demonstrators made gasoline bombs while others dozed while wearing gas masks. Two walked about with bows and quivers of arrows, while many stared at their smartphones.A lull settled on the area as the president of the university said in a video message that that police have agreed to suspend their use of force.Jin-Guang Teng said police would allow protesters to leave and he would accompany them to the police station to ensure their cases would be processed fairly.“I hope that you will accept the proposed temporary suspension of force and leave the campus in a peaceful manner,” he said.It seemed unlikely the protesters would accept the offer given that they would all likely be arrested.A few hundred streamed out of the campus about 8:15 a.m. in an apparent bid to escape, but they were driven back by police tear gas. Some wearing gas masks calmly picked up smoking tear gas canisters and dropped them into heavy-duty bags, but the protesters decided to retreat with a phalanx of officers lined up across the road in the distance.On Sunday, protesters used bows and arrows, and one arrow struck a media liaison officer in the calf. Photos on the department’s Facebook page show the arrow sticking out of the back of the officer’s leg through his pants.As riot police moved in from all sides, some protesters retreated inside the university. Others set fires on bridges leading to it.A huge blaze burned along much of a long footbridge that connects a train station to the campus over the approach to the Cross-Harbour Tunnel, a major road under Hong Kong’s harbor that has been blocked by protesters for days.The use of bows and arrows and gasoline bombs was a sharp escalation of violence by the protesters, who are trying to keep the pressure on Hong Kong leaders, who have rejected most of their demands.The protests started peacefully in early June, sparked by proposed legislation that would have criminal suspects to be extradited to the mainland. But by the time the bill was withdrawn, the protests had hardened and broadened into a resistance movement against the territory’s government and Beijing.Activists see the extradition bill as an example of Hong Kong’s eroding autonomy under Beijing rule since the 1997 handover from colonial power Britain. (AP)See more news-related photo galleries and follow us on Yahoo News Photo Twitter and Tumblr._____Download the Yahoo News app to customize your experience.See more galleries from Yahoo News Photo:PHOTOS: Deadly shooting at California football partyPHOTOS: 10 bronze statues of inspirational women in NYC by Statues for Equality\\\"PHOTOS: California high school shootingPHOTOS: Layered portraits of Hong Kong's masked protestersPHOTOS: Venice flooded from rising tides and rainPHOTOS: Veterans Day 2019 observed at parades, memorials across the U.S.PHOTOS: For Syrian Kurds, and aid workers – the ‘safe zone’ is not so safe \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(prof.predProf(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(FeedDict['linktext'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(FeedDict['title'][0])\n",
    "# print(FeedDict['link'][0])\n",
    "# print(FeedDict['linktext'][0])\n",
    "# print(FeedDict['pubdate'][0])\n",
    "print(FeedDict['tbScore'][0])\n",
    "print(FeedDict['vaderScore'][0])\n",
    "print(FeedDict['prof'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "docs = []\n",
    "for i in range(0,len(FeedDict['title'])):\n",
    "    text = re.sub('&#39','',FeedDict['title'][i])\n",
    "    docs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in docs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = Lda(doc_term_matrix, num_topics=5, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ldamodel.print_topics(num_topics=3)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "lmtzr=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(lmtzr.lemmatize('cats'))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(lmtzr.lemmatize('dogs'))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(lmtzr.lemmatize('impeachment'))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
